{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1417c28a-dc5a-4a20-840a-5001faeceab9",
   "metadata": {},
   "source": [
    "# Propdesk Data Pipeline - Volatility and CPU-bound processes\n",
    "### Example: Calculate volatility for a pair in a given exchange, check if everything is ok and set up a periodic job to keep it updated\n",
    "\n",
    "#### Make sure to have a Tardis key set up on your os environment, e.g.,\n",
    "\n",
    "##### `export TARDIS_KEY=<tardis_key>`\n",
    "Note: lines that actually trigger or create jobs will be commented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef5f39-40fd-4fe6-ad62-52e24fb3be12",
   "metadata": {},
   "source": [
    "First, let's look how the ADA-BRL (cardano-brl) pair is called in Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b93e94-ae4e-4a3b-922b-02875cbd8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adabrl']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from propdesk_services import tardis\n",
    "\n",
    "exchange = 'binance'\n",
    "items_to_search = ['ada', 'brl']\n",
    "\n",
    "all_datasets = tardis.get_all_exchange_datasets(exchange)\n",
    "print([i for i in all_datasets.keys() if all([s in i for s in items_to_search])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddca4285-d49e-46b9-9f1e-6f90e22df91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 'adabrl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05b759-c945-4985-a390-a4a8108a1929",
   "metadata": {},
   "source": [
    "Let's say we want to calculate it from 2022-07-01 to 2022-09-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d85e73e-7dce-4d16-b8cd-e60fa9bcf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = '2022-07-01'\n",
    "date_to = '2022-09-12'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02822c-1a76-423e-9bc9-3ab1d19e5ce7",
   "metadata": {},
   "source": [
    "Then, we can define the parameters of the volatility estimation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbe4c9b-cf18-467e-b4ab-e0c5bcff16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'exchange': exchange,\n",
    "    'pair': pair,\n",
    "    'start_date': date_from,\n",
    "    'end_date': date_to,\n",
    "    'bandwidth': 5,\n",
    "    'lookback_seconds':60,\n",
    "    'log_price': True,\n",
    "    'annualized_volatility': False,\n",
    "    'resampling_rule': '100mS',\n",
    "    'mid_quote_change': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c22cd-526c-4d48-aed3-fd32a3e0ff80",
   "metadata": {},
   "source": [
    "We can simply run this job to have it computed. As an example, let's see if the script is deployed to databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63763aa-0fda-49af-abd0-0e72068d5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spark_ohlcv.py', 'spark_schedule_handler.py', 'spark_seasonality.py', 'spark_volatility_zma.py']\n"
     ]
    }
   ],
   "source": [
    "from propdesk_services.azure_databricks import list_databricks_src_files\n",
    "deployed_files = list_databricks_src_files()\n",
    "print(deployed_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc4a98-ded2-4c15-b441-aee636609922",
   "metadata": {},
   "source": [
    "#### If the script is not deployed, do it by placing it in `propdesk_estimators/spark_jobs` with a name that starts with `spark_` and then run `databricks_deploy.py` FROM THE DIRECTORY `propdesk_estimators/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c6bad-0489-4a1f-a71d-49e1dce388ff",
   "metadata": {},
   "source": [
    "Now we can define the script to run and submit the job. It will return job and run info and a url to check the progress of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886db262-ef1c-43f1-903c-3e6166106db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f'{pair}_{exchange}_vol'\n",
    "job_type = 'cpu_intensive'\n",
    "dataset_type = 'volatility_zma_mqc'\n",
    "script_to_run = 'spark_volatility_zma.py'\n",
    "\n",
    "from propdesk_services.azure_databricks import single_run_job\n",
    "\n",
    "# function commented because it would trigger a run and return the data structure printed below\n",
    "# single_run_job(job_name, script_to_run, params_dict, job_type=job_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbed5bc-8bfc-4f21-a42a-bb46cec35bfa",
   "metadata": {},
   "source": [
    "# ⚠️ ATTENTION - job_type\n",
    "\n",
    "Volatility is a **CPU-BOUND** job. This means the CPU dominates the time to complete the job. We download a small amount of data and work heavily on that little amount of data (we upsample dates to 100mS ticks).\n",
    "That means it makes sense to parallelize not only the calculation (using Spark), but also parallelize the distribution of tasks in the Spark nodes. This increases performance and avoids overload.\n",
    "\n",
    "In jobs that have an start_date and end_date, `single_run_job` will do that work of balancing, splitting the job in up to 100 tasks to be executed in a small ammount of parallel tasks (9-10), a ***batch*** of tasks. \n",
    "When each of those tasks in a ***batch*** ends, it triggers another tasks scheduled for the subsequent ***batch***. That guarantees that:\n",
    "```\n",
    "1 - cluster is not overloaded\n",
    "2 - failure in executing one particular date will not compromise the whole of the operation (just a smaller subset of tasks in cascade triggered in subsequent batches)\n",
    "```\n",
    "\n",
    "Just pass the correct job type and everything will be fine :)\n",
    "# ⚠️ ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7db3b-b064-49a1-8545-1b66fb3a633e",
   "metadata": {},
   "source": [
    "### Connecting to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f473395-0872-44a8-94d8-1c5c2f1733ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from propdesk_estimators.exchange_storage import ExchangeStorage\n",
    "binance = ExchangeStorage(exchange) # -- ExchangeStorage('binance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b972c8a-6b36-4c05-b406-ab69b59091dc",
   "metadata": {},
   "source": [
    "Check for datasets that were already computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98aeebc5-2f95-4724-ad8b-13ce18e18408",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    'dataset_type': 'volatility_zma_mqc',\n",
    "    'pair': pair, \n",
    "    'date_from': date_from, \n",
    "    'date_to': date_to, \n",
    "    'annual': False, \n",
    "    'bandwidth':5,\n",
    "    'log': True,\n",
    "    'lookback': 60,\n",
    "    'resample': '100mS',\n",
    "    'mid_quote_change': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449574ac-d802-4c26-9a8c-9dfb35c48396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already computed datasets in query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-01',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-02',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-03',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-04',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-05',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-06',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-07',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-08',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-09',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-10',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-11',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-12',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-13',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-14',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-15',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-16',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-17',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-18',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-19',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-20',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-21',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-22',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-23',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-24',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-25',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-26',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-27',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-28',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-29',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-30',\n",
       " 'adabrl/volatility_zma_mqc/2022/07/adabrl_volatility_zma_mqc_2022-07-31',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-01',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-02',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-03',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-04',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-05',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-06',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-07',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-08',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-09',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-10',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-11',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-12',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-13',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-14',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-15',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-16',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-17',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-18',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-19',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-20',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-21',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-22',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-23',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-24',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-25',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-26',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-27',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-28',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-29',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-30',\n",
       " 'adabrl/volatility_zma_mqc/2022/08/adabrl_volatility_zma_mqc_2022-08-31',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-01',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-02',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-03',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-04',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-05',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-06',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-07',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-08',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-09',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-10',\n",
       " 'adabrl/volatility_zma_mqc/2022/09/adabrl_volatility_zma_mqc_2022-09-11']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Already computed datasets in query')\n",
    "binance.list_datasets_by_params(query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196710b4-5f6b-4c7b-a6db-34185e1f4c56",
   "metadata": {},
   "source": [
    "## We could have used the method amend to find only the days that we are missing and generate a dict to process those days\n",
    "Note: This notebook was created on 2021/12/15, so the data for this day will not be availabe, and the task related to this day failed. If this notebook is run after this date, the dataset will be available.\n",
    "\n",
    "The amend_datasets_by_params generate a `params_dict` structure that can be used to run jobs to complete the missing days, as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49dd60c-a84d-4e4a-9eb9-71dec0e4ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "query_dict = {\n",
    "    'dataset_type': 'volatility_zma_mqc',\n",
    "    'pair': pair, \n",
    "    'date_from': str(datetime.datetime.utcnow()), \n",
    "    'date_to': str(datetime.datetime.utcnow() + datetime.timedelta(days=2)), \n",
    "    'annual': False, \n",
    "    'bandwidth':5,\n",
    "    'log': True,\n",
    "    'lookback': 60,\n",
    "    'resample': '100mS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3036fb2c-519c-48f6-9735-eb0421353247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing datasets: ['2022-09-13', '2022-09-14', '2022-09-15']\n",
      "\n",
      "Run appropriate job with these parameters:\n",
      "{'dataset_type': 'volatility_zma_mqc', 'pair': 'adabrl', 'annual': False, 'bandwidth': 5, 'log': True, 'lookback': 60, 'resample': '100mS', 'start_date': '2022-09-13', 'end_date': '2022-09-16', 'exchange': 'binance'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binance.amend_datasets_by_params(query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4655030f-cc74-4cc3-a17d-76ae2d27e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_1 = {'dataset_type': 'volatility_zma_mqc', 'pair': 'adabrl', 'annual': False, 'bandwidth': 5, 'log': True, 'lookback': 60, 'resample': '100mS', 'start_date': '2022-09-13', 'end_date': '2022-09-16', 'exchange': 'binance'}\n",
    "\n",
    "# we could just use a for loop\n",
    "# job_1_run_info = single_run_job(job_name+'1', script_to_run, params_dict = job_1, max_tasks_in_job = 100)\n",
    "#job_2_run_info = single_run_job(job_name+'2', script_to_run, params_dict = job_2, max_tasks_in_job = 100)\n",
    "\n",
    "# print(job_1_run_info)\n",
    "# print(job_2_run_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a1f0841-518e-48df-8fcb-9c7ece0d316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from propdesk_services.azure_databricks import get_run\n",
    "# print(get_run(job_1_run_info['run_id'])['state'])\n",
    "# print(get_run(job_2_run_info['run_id'])['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6eee0-3e3d-4882-96a4-68bb8b321e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### After jobs are done, the datasets should be uploaded to Azure Storage, and the same query performed before should return those datasets\n",
    "amend will return an list with 2021/15/12 missing, because task failed (data was not available at the time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78cb8a-c804-4919-9ae4-7c497134435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance.list_datasets_by_params(query_dict, amend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b403a52-733e-48d4-b551-72d7ed46ebba",
   "metadata": {},
   "source": [
    "### With the module `propdesk_services.exchange_storage`, we can interact with those datasets. Let's straight up get a dataframe with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cf330b-745b-431f-b63e-b22d3a06fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files saved to: /tmp/tmplv2g94h2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>volatility_estimation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-01 00:00:00.000</td>\n",
       "      <td>2.448069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-01 00:00:00.100</td>\n",
       "      <td>2.448069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-01 00:00:00.200</td>\n",
       "      <td>2.448069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-01 00:00:00.300</td>\n",
       "      <td>2.448069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01 00:00:00.400</td>\n",
       "      <td>2.448069e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858589</th>\n",
       "      <td>2022-07-01 23:59:59.500</td>\n",
       "      <td>8.223578e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858590</th>\n",
       "      <td>2022-07-01 23:59:59.600</td>\n",
       "      <td>7.616000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858591</th>\n",
       "      <td>2022-07-01 23:59:59.700</td>\n",
       "      <td>7.616000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858592</th>\n",
       "      <td>2022-07-01 23:59:59.800</td>\n",
       "      <td>7.616000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858593</th>\n",
       "      <td>2022-07-01 23:59:59.900</td>\n",
       "      <td>7.616000e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime  volatility_estimation\n",
       "0      2022-07-01 00:00:00.000           2.448069e-07\n",
       "1      2022-07-01 00:00:00.100           2.448069e-07\n",
       "2      2022-07-01 00:00:00.200           2.448069e-07\n",
       "3      2022-07-01 00:00:00.300           2.448069e-07\n",
       "4      2022-07-01 00:00:00.400           2.448069e-07\n",
       "...                        ...                    ...\n",
       "858589 2022-07-01 23:59:59.500           8.223578e-08\n",
       "858590 2022-07-01 23:59:59.600           7.616000e-08\n",
       "858591 2022-07-01 23:59:59.700           7.616000e-08\n",
       "858592 2022-07-01 23:59:59.800           7.616000e-08\n",
       "858593 2022-07-01 23:59:59.900           7.616000e-08\n",
       "\n",
       "[858594 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from propdesk_services.exchange_storage import get_dataframe_by_params\n",
    "\n",
    "query_dict = {\n",
    "    'dataset_type': 'volatility_zma_mqc',\n",
    "    'pair': 'adabrl', \n",
    "    'date_from': '2022-07-01', \n",
    "    'date_to': '2022-07-02', \n",
    "    'annual': False, \n",
    "    'bandwidth':5,\n",
    "    'log': True,\n",
    "    'lookback': 60,\n",
    "    'resample': '100mS'\n",
    "}\n",
    "\n",
    "\n",
    "# pass the flag keep_local to keep raw files instead of downloading them again if needed\n",
    "adabrl_vol_df = get_dataframe_by_params(exchange_str='binance', params_dict=query_dict, keep_local=True)\n",
    "adabrl_vol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56306f-bb7b-42c2-9d7e-50797ff19e19",
   "metadata": {},
   "source": [
    "# Success :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37207e-8fd0-4b12-b9d1-e9a6da9d1849",
   "metadata": {},
   "source": [
    "## Creating a periodic job\n",
    "Now, after using, checking data, etc., we can create a periodic (weekly or daily) job to keep this dataset updated. We'll setup it to run weekly on Mondays at 04:00 AM Sao Paulo time, to use the cluster in an idle time. \n",
    "\n",
    "## Ideally, **check Databricks UI to see if there are jobs scheduled for those times and day to avoid overloading the cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bedf78-3ff8-4543-8655-c4cbee7d9cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': {'job_id': 837105722299197},\n",
       " 'schedule_job': {'job_id': 874249017617680}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from propdesk_services.azure_databricks import create_periodic_job\n",
    "\n",
    "pair = 'btcusdt'\n",
    "exchange = 'binance'\n",
    "\n",
    "# weekly job\n",
    "job_name = f'daily_volatility_zma_mqc_{pair}_{exchange}'\n",
    "\n",
    "# make sure to have a schedule that is compatible with the period\n",
    "job_schedule = \"0 15 1 ? * *\"\n",
    "\n",
    "period = 'daily'\n",
    "# no need for start_date and end_date in weekly jobs \n",
    "job_params = {\n",
    "    'exchange': exchange,\n",
    "    'pair': pair,\n",
    "    'bandwidth': 5,\n",
    "    'lookback_seconds':60,\n",
    "    'log_price': True,\n",
    "    'annualized_volatility': False,\n",
    "    'resampling_rule': '100mS'\n",
    "}\n",
    "\n",
    "create_periodic_job(job_name_str=job_name,\n",
    "                    filename_str=script_to_run,\n",
    "                    params_dict=job_params,\n",
    "                    period=period,\n",
    "                    cron_expression_str=job_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1bfdd-6017-4b64-a2ef-5aff899b2c75",
   "metadata": {},
   "source": [
    "## That's it. **check Databricks UI to make sure everything is ok**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf7bca-9ce3-4c1c-90a4-e52908785ba7",
   "metadata": {},
   "source": [
    "### Have fun, move fast, break things, buy btc (or dcr or algorand) ⚡.\n",
    "#### -- Propdesk Transfero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02e127-ef42-4e8a-8c01-ee0745f45669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
